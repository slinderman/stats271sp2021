{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IoYdLutn7dUa"
   },
   "source": [
    "# HW5: Topic Models and LDA\n",
    "\n",
    "\n",
    "**STATS271/371: Applied Bayesian Statistics**\n",
    "\n",
    "_Stanford University. Spring, 2021._\n",
    "\n",
    "---\n",
    "\n",
    "**Name:** _Your name here_\n",
    "\n",
    "**Names of any collaborators:** _Names here_\n",
    "\n",
    "*Due: 11:59pm Monday, May 10, 2021 via GradeScope*\n",
    "\n",
    "---\n",
    "\n",
    "Recall the following generatize model for LDA. Suppose we have $K$ topics and $N$ documents.\n",
    "\n",
    "For each topic $k \\leq K$, draw a topic \n",
    "$$\\eta_k \\sim \\text{Dir}(\\phi)$$\n",
    "\n",
    "Then, for each document $n \\leq N$, draw topic proportions \n",
    "$$\\pi_n \\sim \\text{Dir}(\\alpha)$$\n",
    "\n",
    "Finally, for each word $l$ in document $n$, first draw a topic assignment \n",
    "$$\n",
    "z_{n,l} \\mid \\pi_n \\sim \\text{Cat}(\\pi_n)\n",
    "$$\n",
    "and draw a word\n",
    "$$\n",
    "x_{n,l} \\mid z_{n,l} \\sim \\text{Cat}(z_{n,l})\n",
    "$$\n",
    "\n",
    "As mentioned in class, while this formulation is easier to present, it's more efficient to represent the documents as sparse vectors of _word counts_, $\\mathbf{y}_n \\in \\mathbb{N}^V$ where $y_{n,v} = \\sum_{l=1}^L \\mathbb{I}[x_{n,l} = v]$. \n",
    "\n",
    "In this assignment, we will be re-exploring the Federalist papers in their entirety. We've provided a $N \\times V$ dataframe of the essays represented as word counts. The rows of the data frame correspond to the 85 individual essays and the columns correspond to the 5320 words in the vocabulary. We have already preprocessed the raw essays to remove very common and very infrequent words.\n",
    "\n",
    "Using this data, we will fit a topic model and do some analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unequivocal</th>\n",
       "      <th>experience</th>\n",
       "      <th>inefficacy</th>\n",
       "      <th>subsisting</th>\n",
       "      <th>federal</th>\n",
       "      <th>called</th>\n",
       "      <th>deliberate</th>\n",
       "      <th>new</th>\n",
       "      <th>constitution</th>\n",
       "      <th>united</th>\n",
       "      <th>...</th>\n",
       "      <th>chancery</th>\n",
       "      <th>jurisprudence</th>\n",
       "      <th>reexamination</th>\n",
       "      <th>writ</th>\n",
       "      <th>commonlaw</th>\n",
       "      <th>intent</th>\n",
       "      <th>refutation</th>\n",
       "      <th>habeas</th>\n",
       "      <th>corpus</th>\n",
       "      <th>clerks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows Ã— 5320 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    unequivocal  experience  inefficacy  subsisting  federal  called  \\\n",
       "0           1.0         1.0         1.0         1.0      1.0     1.0   \n",
       "1           0.0         2.0         0.0         0.0      2.0     1.0   \n",
       "2           0.0         1.0         0.0         0.0      2.0     0.0   \n",
       "3           0.0         2.0         0.0         0.0      0.0     1.0   \n",
       "4           0.0         1.0         0.0         0.0      0.0     0.0   \n",
       "..          ...         ...         ...         ...      ...     ...   \n",
       "80          0.0         0.0         0.0         0.0      6.0     1.0   \n",
       "81          0.0         0.0         0.0         0.0     12.0     0.0   \n",
       "82          0.0         1.0         0.0         0.0      7.0     2.0   \n",
       "83          0.0         0.0         0.0         0.0      2.0     1.0   \n",
       "84          0.0         2.0         0.0         0.0      0.0     1.0   \n",
       "\n",
       "    deliberate  new  constitution  united  ...  chancery  jurisprudence  \\\n",
       "0          1.0  5.0           7.0     1.0  ...       0.0            0.0   \n",
       "1          0.0  2.0           0.0     3.0  ...       0.0            0.0   \n",
       "2          0.0  1.0           0.0     4.0  ...       0.0            0.0   \n",
       "3          0.0  0.0           0.0     2.0  ...       0.0            0.0   \n",
       "4          0.0  0.0           0.0     0.0  ...       0.0            0.0   \n",
       "..         ...  ...           ...     ...  ...       ...            ...   \n",
       "80         1.0  8.0          12.0     8.0  ...       1.0            1.0   \n",
       "81         0.0  2.0           4.0     5.0  ...       0.0            0.0   \n",
       "82         2.0  9.0          13.0     6.0  ...       7.0            1.0   \n",
       "83         0.0  9.0          26.0    12.0  ...       0.0            0.0   \n",
       "84         0.0  4.0          13.0     2.0  ...       0.0            0.0   \n",
       "\n",
       "    reexamination  writ  commonlaw  intent  refutation  habeas  corpus  clerks  \n",
       "0             0.0   0.0        0.0     0.0         0.0     0.0     0.0     0.0  \n",
       "1             0.0   0.0        0.0     0.0         0.0     0.0     0.0     0.0  \n",
       "2             0.0   0.0        0.0     0.0         0.0     0.0     0.0     0.0  \n",
       "3             0.0   0.0        0.0     0.0         0.0     0.0     0.0     0.0  \n",
       "4             0.0   0.0        0.0     0.0         0.0     0.0     0.0     0.0  \n",
       "..            ...   ...        ...     ...         ...     ...     ...     ...  \n",
       "80            5.0   1.0        1.0     0.0         0.0     0.0     0.0     0.0  \n",
       "81            0.0   0.0        0.0     1.0         0.0     0.0     0.0     0.0  \n",
       "82            1.0   0.0        5.0     2.0         2.0     1.0     1.0     1.0  \n",
       "83            0.0   2.0        0.0     0.0         0.0     3.0     3.0     1.0  \n",
       "84            0.0   0.0        0.0     0.0         1.0     0.0     0.0     0.0  \n",
       "\n",
       "[85 rows x 5320 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('tokenized_fed.csv', index_col = 0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Fit LDA on this data set.\n",
    "\n",
    "Fit a 10 topic LDA on the data using CAVI. For each topic, output the top 5 words. You might find the structure in the [Poisson matrix factorization notebook](https://github.com/slinderman/stats271sp2021/blob/main/notebooks/Lap_5_Poisson_MF.ipynb) helpful. (Note that that notebook used the JAX backend available in the `tfp-nightly` package, but you could have used the regular [TensorFlow Probability](tensorflow.org/probability/api_docs/python/tfp) package instead. The nice thing about TFP is that its functions broadcast nicely, which is helpful when we have lots of factors in the mean field variational posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Analysis/Exploration\n",
    "\n",
    "Using the model, for each essay assign it the most likely topic. For the undisputed papers, plot the histogram of this topic usage vs author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load authorship\n",
    "authorship = pd.read_csv('authorship.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Short Answer questions\n",
    "\n",
    "### Part a)\n",
    "\n",
    "Explain what approach you would take if you wanted to use LDA to help settle disputed authorship. How would you incorporate authorship by different authors into your model?\n",
    "\n",
    "### Part b)\n",
    "\n",
    "A shortcoming of LDA discussed in this class is the fact that the model is exchangeable (which is not a very reasonable assumption for essays). What would you do to address this shortcoming? In essence, how could you account for dependencies between words that are near each other in the essay?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_OnB5kf-k7B0"
   },
   "source": [
    "# Submission Instructions\n",
    "\n",
    "\n",
    "**Formatting:** check that your code does not exceed 80 characters in line width. If you're working in Colab, you can set _Tools &rarr; Settings &rarr; Editor &rarr; Vertical ruler column_ to 80 to see when you've exceeded the limit. \n",
    "\n",
    "Download your notebook in .ipynb format and use the following commands to convert it to PDF:\n",
    "```\n",
    "jupyter nbconvert --to pdf hw5_yourname.ipynb\n",
    "```\n",
    "\n",
    "**Dependencies:**\n",
    "\n",
    "- `nbconvert`: If you're using Anaconda for package management, \n",
    "```\n",
    "conda install -c anaconda nbconvert\n",
    "```\n",
    "\n",
    "**Upload** your .ipynb and .pdf files to Gradescope. \n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of STATS271 HW1: Bayesian Linear Regression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
